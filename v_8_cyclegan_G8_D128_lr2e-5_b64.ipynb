{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hRm9o68SLGo"
      },
      "source": [
        "# Individual Project: Unsupervised CT Denoising with CycleGAN\n",
        "This notebook is provided for unsupervised CT denoising task with cycleGAN.\n",
        "\n",
        "###Table of Contents\n",
        "\n",
        "I. Data: Google Drive, Dataloader\n",
        "\n",
        "II. Network: Generator / Discriminator\n",
        "\n",
        "III. Other functions\n",
        "\n",
        "IV. Training\n",
        "\n",
        "V. Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJb_MPk-S5L_"
      },
      "source": [
        "## I. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h01yiT-S9Hq"
      },
      "source": [
        "### 1. Google Drive\n",
        "If you want to use data in your Google drive, you have to mount your google drive first.\n",
        "It makes possible to load data from the drive, save results in the drive, etc. \n",
        "If you try to mount Google Drive, a link for authentication code will be given. \n",
        "Then, follow the link, get your authentication code, and enter your code in the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEIVCE\"]=\"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6VDOjbfiYe9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an example image\n",
        "img = np.load('./AAPM_data/train/full_dose/1.npy')\n",
        "print(type(img))\n",
        "print(img.shape)\n",
        "img = np.load('./AAPM_data/train/quarter_dose/1.npy')\n",
        "print(type(img))\n",
        "print(img.shape)\n",
        "\n",
        "# Change linear attenuation coefficient into HU values\n",
        "img = (img - 0.0192) / 0.0192 * 1000\n",
        "# Clip the CT image with [-1000, 1000] HU\n",
        "img = np.clip(img, -1000, 1000)\n",
        "\n",
        "# Plot the example image\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK0k3ee6WMss"
      },
      "source": [
        "### 2. Dataloader\n",
        "Before the training of cycleGAN, data preprocessing (e.g. cliping, normalization) is required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v3G5AI-nonP-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# CT dataset\n",
        "class CT_Dataset(Dataset):\n",
        "  def __init__(self, path, transform):\n",
        "    # Path of 'full_dose' and 'quarter_dose' folders\n",
        "    self.path_full = join(path, 'full_dose')\n",
        "    self.path_quarter = join(path, 'quarter_dose')\n",
        "    self.transform = transform\n",
        "\n",
        "    # File list of full dose data\n",
        "    self.file_full = list()\n",
        "    for file_name in sorted(listdir(self.path_full)):\n",
        "      self.file_full.append(file_name)\n",
        "    random.seed(0)\n",
        "    random.shuffle(self.file_full)\n",
        "    \n",
        "    # File list of quarter dose data\n",
        "    self.file_quarter = list()\n",
        "    for file_name in sorted(listdir(self.path_quarter)):\n",
        "      self.file_quarter.append(file_name)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return min(len(self.file_full), len(self.file_quarter))\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    # Load full dose/quarter dose data\n",
        "    x_F = np.load(join(self.path_full, self.file_full[idx]))\n",
        "    x_Q = np.load(join(self.path_quarter, self.file_quarter[idx]))\n",
        "\n",
        "    # Convert to HU scale\n",
        "    x_F = (x_F - 0.0192) / 0.0192 * 1000\n",
        "    x_Q = (x_Q - 0.0192) / 0.0192 * 1000\n",
        "\n",
        "    # Normalize images\n",
        "    x_F[x_F < -1000] = -1000\n",
        "    x_Q[x_Q < -1000] = -1000\n",
        "\n",
        "    x_F = x_F / 4000\n",
        "    x_Q = x_Q / 4000\n",
        "\n",
        "    # Apply transform\n",
        "    x_F = self.transform(x_F)\n",
        "    x_Q = self.transform(x_Q)\n",
        "\n",
        "    file_name = self.file_quarter[idx]\n",
        "\n",
        "    return x_F, x_Q, file_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2GnXM-eXM9M"
      },
      "source": [
        "Because the size of CT images is too large, we have to crop the images into small size patches for training.\n",
        "After training with patches, the whole size image will be used for the test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HTWq-6WKXb64"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# Transform for the random crop\n",
        "class RandomCrop(object):\n",
        "  def __init__(self, patch_size):\n",
        "    self.patch_size = patch_size\n",
        "  \n",
        "  def __call__(self, img):\n",
        "    # Randomly crop the image into a patch with the size [self.patch_size, self.patch_size]\n",
        "    w, h = img.size(-1), img.size(-2)\n",
        "    i = random.randint(0, h - self.patch_size)\n",
        "    j = random.randint(0, w - self.patch_size)\n",
        "\n",
        "    return img[:, i:i + self.patch_size, j:j + self.patch_size]\n",
        "\n",
        "\n",
        "# Make dataloader for training/test\n",
        "def make_dataloader(path, batch_size):\n",
        "  # Path of 'train' and 'test' folders\n",
        "  path_train = join(path, 'train')\n",
        "  path_test = join(path, 'test')\n",
        "\n",
        "  # Transform for training data: convert to tensor, random horizontal/verical flip, random crop\n",
        "  # You can change transform if you want.\n",
        "  train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
        "    RandomCrop(128)\n",
        "  ])\n",
        "\n",
        "  # Transform for test data: convert to tensor\n",
        "  test_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  # Generate CT dataset for training/test\n",
        "  train_dataset = CT_Dataset(path_train, train_transform)\n",
        "  test_dataset = CT_Dataset(path_test, test_transform)\n",
        "  \n",
        "  # Generate dataloader for training/test\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "  return train_dataloader, test_dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z2QlnrKbVr8"
      },
      "source": [
        "## II. Network: Generator / Discriminator\n",
        "You have to implement basic blocks for generator/discriminator.\n",
        "Refer to the 'ConvBlock', and make your own blocks for building generators/discriminators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NI1fbN6R-qBl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Example convolution block. You don't have to use this block.\n",
        "# (Convolution, Batch normalization, ReLU) x 2\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, mid_channels, out_channels):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(mid_channels, affine=True, track_running_stats=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(mid_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels, affine=True, track_running_stats=True),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    return out\n",
        "  \n",
        "# thum_copy: from networks.py\n",
        "# You can implement other building blocks for making generator and discriminator.\n",
        "######################\n",
        "\n",
        "class ResnetGenerator(nn.Module):\n",
        "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
        "\n",
        "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
        "        \"\"\"Construct a Resnet-based generator\n",
        "\n",
        "        Parameters:\n",
        "            input_nc (int)      -- the number of channels in input images\n",
        "            output_nc (int)     -- the number of channels in output images\n",
        "            ngf (int)           -- the number of filters in the last conv layer\n",
        "            norm_layer          -- normalization layer\n",
        "            use_dropout (bool)  -- if use dropout layers\n",
        "            n_blocks (int)      -- the number of ResNet blocks\n",
        "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
        "        \"\"\"\n",
        "        assert(n_blocks >= 0)\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
        "                 norm_layer(ngf),\n",
        "                 nn.ReLU(True)]\n",
        "\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):  # add downsampling layers\n",
        "            mult = 2 ** i\n",
        "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
        "                      norm_layer(ngf * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        mult = 2 ** n_downsampling\n",
        "        for i in range(n_blocks):       # add ResNet blocks\n",
        "\n",
        "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "\n",
        "        for i in range(n_downsampling):  # add upsampling layers\n",
        "            mult = 2 ** (n_downsampling - i)\n",
        "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                         kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1,\n",
        "                                         bias=use_bias),\n",
        "                      norm_layer(int(ngf * mult / 2)),\n",
        "                      nn.ReLU(True)]\n",
        "        model += [nn.ReflectionPad2d(3)]\n",
        "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward\"\"\"\n",
        "        return self.model(input)\n",
        "\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    \"\"\"Define a Resnet block\"\"\"\n",
        "\n",
        "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        \"\"\"Initialize the Resnet block\n",
        "\n",
        "        A resnet block is a conv block with skip connections\n",
        "        We construct a conv block with build_conv_block function,\n",
        "        and implement skip connections in <forward> function.\n",
        "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
        "        \"\"\"\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
        "\n",
        "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        \"\"\"Construct a convolutional block.\n",
        "\n",
        "        Parameters:\n",
        "            dim (int)           -- the number of channels in the conv layer.\n",
        "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
        "            norm_layer          -- normalization layer\n",
        "            use_dropout (bool)  -- if use dropout layers.\n",
        "            use_bias (bool)     -- if the conv layer uses bias or not\n",
        "\n",
        "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
        "        \"\"\"\n",
        "        conv_block = []\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function (with skip connections)\"\"\"\n",
        "        out = x + self.conv_block(x)  # add skip connections\n",
        "        return out\n",
        "\n",
        "\n",
        "class UnetGenerator(nn.Module):\n",
        "    \"\"\"Create a Unet-based generator\"\"\"\n",
        "\n",
        "    def __init__(self, input_nc, output_nc, num_downs, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        \"\"\"Construct a Unet generator\n",
        "        Parameters:\n",
        "            input_nc (int)  -- the number of channels in input images\n",
        "            output_nc (int) -- the number of channels in output images\n",
        "            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n",
        "                                image of size 128x128 will become of size 1x1 # at the bottleneck\n",
        "            ngf (int)       -- the number of filters in the last conv layer\n",
        "            norm_layer      -- normalization layer\n",
        "\n",
        "        We construct the U-Net from the innermost layer to the outermost layer.\n",
        "        It is a recursive process.\n",
        "        \"\"\"\n",
        "        super(UnetGenerator, self).__init__()\n",
        "        # construct unet structure\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)  # add the innermost layer\n",
        "        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n",
        "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  # add the outermost layer\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward\"\"\"\n",
        "        return self.model(input)\n",
        "\n",
        "\n",
        "class UnetSkipConnectionBlock(nn.Module):\n",
        "    \"\"\"Defines the Unet submodule with skip connection.\n",
        "        X -------------------identity----------------------\n",
        "        |-- downsampling -- |submodule| -- upsampling --|\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
        "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        \"\"\"Construct a Unet submodule with skip connections.\n",
        "\n",
        "        Parameters:\n",
        "            outer_nc (int) -- the number of filters in the outer conv layer\n",
        "            inner_nc (int) -- the number of filters in the inner conv layer\n",
        "            input_nc (int) -- the number of channels in input images/features\n",
        "            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n",
        "            outermost (bool)    -- if this module is the outermost module\n",
        "            innermost (bool)    -- if this module is the innermost module\n",
        "            norm_layer          -- normalization layer\n",
        "            use_dropout (bool)  -- if use dropout layers.\n",
        "        \"\"\"\n",
        "        super(UnetSkipConnectionBlock, self).__init__()\n",
        "        self.outermost = outermost\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "        if input_nc is None:\n",
        "            input_nc = outer_nc\n",
        "        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=use_bias)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = norm_layer(inner_nc)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = norm_layer(outer_nc)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "\n",
        "            if use_dropout:\n",
        "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
        "            else:\n",
        "                model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:   # add skip connections\n",
        "            return torch.cat([x, self.model(x)], 1)\n",
        "\n",
        "class NLayerDiscriminator(nn.Module):\n",
        "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
        "\n",
        "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
        "        \"\"\"Construct a PatchGAN discriminator\n",
        "\n",
        "        Parameters:\n",
        "            input_nc (int)  -- the number of channels in input images\n",
        "            ndf (int)       -- the number of filters in the last conv layer\n",
        "            n_layers (int)  -- the number of conv layers in the discriminator\n",
        "            norm_layer      -- normalization layer\n",
        "        \"\"\"\n",
        "        super(NLayerDiscriminator, self).__init__()\n",
        "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        kw = 4\n",
        "        padw = 1\n",
        "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2 ** n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "                norm_layer(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2 ** n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "            norm_layer(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward.\"\"\"\n",
        "        return self.model(input)\n",
        "\n",
        "# methods\n",
        "def get_norm_layer(norm_type='instance'):\n",
        "    \"\"\"Return a normalization layer\n",
        "\n",
        "    Parameters:\n",
        "        norm_type (str) -- the name of the normalization layer: batch | instance | none\n",
        "\n",
        "    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n",
        "    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n",
        "    \"\"\"\n",
        "    if norm_type == 'batch':\n",
        "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
        "    elif norm_type == 'instance':\n",
        "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
        "    elif norm_type == 'none':\n",
        "        def norm_layer(x):\n",
        "            return Identity()\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
        "    return norm_layer\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer, opt):\n",
        "    \"\"\"Return a learning rate scheduler\n",
        "\n",
        "    Parameters:\n",
        "        optimizer          -- the optimizer of the network\n",
        "        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions．　\n",
        "                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n",
        "\n",
        "    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
        "    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
        "    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n",
        "    See https://pytorch.org/docs/stable/optim.html for more details.\n",
        "    \"\"\"\n",
        "    if opt.lr_policy == 'linear':\n",
        "        def lambda_rule(epoch):\n",
        "            lr_l = 1.0 - max(0, epoch + opt.epoch_count - opt.n_epochs) / float(opt.n_epochs_decay + 1)\n",
        "            return lr_l\n",
        "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
        "    elif opt.lr_policy == 'step':\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=opt.lr_decay_iters, gamma=0.1)\n",
        "    elif opt.lr_policy == 'plateau':\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
        "    elif opt.lr_policy == 'cosine':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=opt.n_epochs, eta_min=0)\n",
        "    else:\n",
        "        return NotImplementedError('learning rate policy [%s] is not implemented', opt.lr_policy)\n",
        "    return scheduler\n",
        "\n",
        "def init_weights_(net, init_type='normal', init_gain=0.02):\n",
        "    \"\"\"Initialize network weights.\n",
        "\n",
        "    Parameters:\n",
        "        net (network)   -- network to be initialized\n",
        "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
        "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
        "\n",
        "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
        "    work better for some applications. Feel free to try yourself.\n",
        "    \"\"\"\n",
        "    def init_func(m):  # define the initialization function\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            elif init_type == 'orthogonal':\n",
        "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    print('initialize network with %s' % init_type)\n",
        "    net.apply(init_func)  # apply the initialization function <init_func>\n",
        "\n",
        "\n",
        "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
        "    \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
        "    Parameters:\n",
        "        net (network)      -- the network to be initialized\n",
        "        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
        "        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
        "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
        "\n",
        "    Return an initialized network.\n",
        "    \"\"\"\n",
        "    if len(gpu_ids) > 0:\n",
        "        assert(torch.cuda.is_available())\n",
        "        net.to(gpu_ids[0])\n",
        "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
        "    init_weights_(net, init_type, init_gain=init_gain)\n",
        "    return net\n",
        "\n",
        "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
        "    \"\"\"Create a generator\n",
        "\n",
        "    Parameters:\n",
        "        input_nc (int) -- the number of channels in input images\n",
        "        output_nc (int) -- the number of channels in output images\n",
        "        ngf (int) -- the number of filters in the last conv layer\n",
        "        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n",
        "        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n",
        "        use_dropout (bool) -- if use dropout layers.\n",
        "        init_type (str)    -- the name of our initialization method.\n",
        "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
        "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
        "\n",
        "    Returns a generator\n",
        "\n",
        "    Our current implementation provides two types of generators:\n",
        "        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
        "        The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
        "\n",
        "        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n",
        "        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n",
        "        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n",
        "\n",
        "\n",
        "    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n",
        "    \"\"\"\n",
        "    net = None\n",
        "    norm_layer = get_norm_layer(norm_type=norm)\n",
        "\n",
        "    if netG == 'resnet_9blocks':\n",
        "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=9)\n",
        "    elif netG == 'resnet_6blocks':\n",
        "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6)\n",
        "    elif netG == 'unet_128':\n",
        "        net = UnetGenerator(input_nc, output_nc, 7, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "    elif netG == 'unet_256':\n",
        "        net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "    else:\n",
        "        raise NotImplementedError('Generator model name [%s] is not recognized' % netG)\n",
        "    return init_net(net, init_type, init_gain, gpu_ids)\n",
        "\n",
        "\n",
        "def define_D(input_nc, ndf, netD, n_layers_D=3, norm='batch', init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
        "    \"\"\"Create a discriminator\n",
        "\n",
        "    Parameters:\n",
        "        input_nc (int)     -- the number of channels in input images\n",
        "        ndf (int)          -- the number of filters in the first conv layer\n",
        "        netD (str)         -- the architecture's name: basic | n_layers | pixel\n",
        "        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n",
        "        norm (str)         -- the type of normalization layers used in the network.\n",
        "        init_type (str)    -- the name of the initialization method.\n",
        "        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n",
        "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
        "\n",
        "    Returns a discriminator\n",
        "\n",
        "    Our current implementation provides three types of discriminators:\n",
        "        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n",
        "        It can classify whether 70×70 overlapping patches are real or fake.\n",
        "        Such a patch-level discriminator architecture has fewer parameters\n",
        "        than a full-image discriminator and can work on arbitrarily-sized images\n",
        "        in a fully convolutional fashion.\n",
        "\n",
        "        [n_layers]: With this mode, you can specify the number of conv layers in the discriminator\n",
        "        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n",
        "\n",
        "        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n",
        "        It encourages greater color diversity but has no effect on spatial statistics.\n",
        "\n",
        "    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n",
        "    \"\"\"\n",
        "    net = None\n",
        "    norm_layer = get_norm_layer(norm_type=norm)\n",
        "\n",
        "    if netD == 'basic':  # default PatchGAN classifier\n",
        "        net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer)\n",
        "    elif netD == 'n_layers':  # more options\n",
        "        net = NLayerDiscriminator(input_nc, ndf, n_layers_D, norm_layer=norm_layer)\n",
        "    elif netD == 'pixel':     # classify if each pixel is real or fake\n",
        "        net = PixelDiscriminator(input_nc, ndf, norm_layer=norm_layer)\n",
        "    else:\n",
        "        raise NotImplementedError('Discriminator model name [%s] is not recognized' % netD)\n",
        "    return init_net(net, init_type, init_gain, gpu_ids)\n",
        "\n",
        "######################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y58QwHbicc_f"
      },
      "source": [
        "### 1. Generator\n",
        "Now, implement the generator and discriminator below.\n",
        "You are free to choose the structure of the generator (e.g. U-Net, ResNet), but it should contain residual path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GAMI3pbWbhE9"
      },
      "outputs": [],
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, ngf):\n",
        "    super(Generator, self).__init__()\n",
        "    # in_channels: the number of channels of the input\n",
        "    # out_channels: the number of channels of the output\n",
        "    # ngf: the number of convolution filters of the first layer\n",
        "    ######################\n",
        "    # Your code\n",
        "    self.netG = define_G(in_channels, out_channels, ngf, \"unet_128\")\n",
        "    ######################\n",
        "  \n",
        "  def forward(self, x):\n",
        "    ######################\n",
        "    out = self.netG(x)\n",
        "    ######################\n",
        "\n",
        "    # Residual path: final output = output + input\n",
        "    ######################\n",
        "    x = x + out\n",
        "    return x\n",
        "    ######################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndKmNFTse53O"
      },
      "source": [
        "### 2. Discriminator\n",
        "You have to construct PatchGAN structure for the discriminator as shown in PPT slide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xqza1MTYe-70"
      },
      "outputs": [],
      "source": [
        "# Discriminator (PatchGAN)\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels, ndf):\n",
        "    super(Discriminator, self).__init__()\n",
        "    # in_channels: the number of channels of the input\n",
        "    # ndf: the number of convolution filters of the first layer\n",
        "    ######################\n",
        "    self.netD = define_D(in_channels, ndf, \"basic\")\n",
        "    ######################\n",
        "  \n",
        "  def forward(self, x):\n",
        "    ######################\n",
        "    return self.netD(x)\n",
        "    ######################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2hqiJnkemP3"
      },
      "source": [
        "## III. Other functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RDG_8KraXLM7"
      },
      "outputs": [],
      "source": [
        "from torch.nn import init\n",
        "\n",
        "\n",
        "# initialize parameters of neural networks\n",
        "def init_weights(net):\n",
        "  def init_func(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "      init.normal_(m.weight.data, 0.0, 0.02)\n",
        "      if hasattr(m, 'bias') and m.bias is not None:\n",
        "        init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "      init.normal_(m.weight.data, 1.0, 0.02)\n",
        "      init.constant_(m.bias.data, 0.0)\n",
        "    \n",
        "  print('Initialize network.')\n",
        "  net.apply(init_func)\n",
        "\n",
        "\n",
        "# Calculate average loss during one epoch\n",
        "class Mean:\n",
        "  def __init__(self):\n",
        "    self.numel = 0\n",
        "    self.mean = 0\n",
        "  \n",
        "  def __call__(self, val):\n",
        "    self.mean = self.mean * (self.numel / (self.numel + 1)) + val / (self.numel + 1)\n",
        "    self.numel += 1\n",
        "  \n",
        "  def result(self):\n",
        "    return self.mean\n",
        "\n",
        "\n",
        "# Show input and output images during training\n",
        "def show_imgs(imgs, img_path, epoch):\n",
        "  FQF = np.concatenate(imgs[:3], axis=2)\n",
        "  QFQ = np.concatenate(imgs[3:], axis=2)\n",
        "  img_array = np.squeeze(np.concatenate([FQF, QFQ], axis=1))\n",
        "\n",
        "  img_array = img_array * 4000\n",
        "  img_array = np.clip(img_array, -1000, 1000)\n",
        "\n",
        "  plt.imshow(img_array, cmap='gray')\n",
        "  plt.imsave(os.path.join(img_path, str(epoch)+'.png'), img_array, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Set 'requires_grad' of the networks\n",
        "def set_requires_grad(nets, requires_grad=False):\n",
        "  if not isinstance(nets, list):\n",
        "    nets = [nets]\n",
        "  for net in nets:\n",
        "    if net is not None:\n",
        "      for param in net.parameters():\n",
        "        param.requires_grad = requires_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVWlp65Sfs6P"
      },
      "source": [
        "## IV. Training\n",
        "Before training the network, some hyperparameters should be defined as follows.\n",
        "You can change the value of hyperparameters if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G63jcZgQf66Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from os import makedirs\n",
        "from os.path import isdir\n",
        "\n",
        "# Hyperparameters\n",
        "# You can change hyperparameters to find your best performance in your architecture.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "batch_size = 32\n",
        "lambda_cycle = 10\n",
        "lambda_iden = 5\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "num_epoch = 200\n",
        "lr = 2e-5\n",
        "\n",
        "# Path for saving the checkpoint\n",
        "path_checkpoint = './checkpoint'\n",
        "if not isdir(path_checkpoint):\n",
        "  makedirs(path_checkpoint)\n",
        "\n",
        "model_name = 'v_7_cyclegan_G8_D128_lr2e-5_b64'\n",
        "\n",
        "# Path for saving results\n",
        "path_result = join(path_checkpoint, model_name)\n",
        "path_image = join(path_checkpoint, model_name, \"images\")\n",
        "if not isdir(path_result):\n",
        "  makedirs(path_result)\n",
        "  makedirs(path_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaxBVSlbiNIq"
      },
      "source": [
        "```model_name``` is the name of the model, and it will be used for saving the model.\n",
        "If you want to continue the training from the last checkpoint, set ```model_name``` as the name of the saved model.\n",
        "However, if you want to train a new model, you have to change ```model_name```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiIRV1O1gL90"
      },
      "source": [
        "Next, make dataloaders, networks, optimizers, and define loss functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1e_uJN1PCf-"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# path of dataset (change the path according to your setting)\n",
        "path_data = './AAPM_data'\n",
        "\n",
        "# Make dataloaders\n",
        "train_dataloader, test_dataloader = make_dataloader(path_data, batch_size)\n",
        "\n",
        "# Make generators (G_F2Q: full to quarter / G_Q2F: quarter to full)\n",
        "####################\n",
        "G_F2Q = Generator(1, 1, 8).to(device)\n",
        "G_Q2F = Generator(1, 1, 8).to(device)\n",
        "####################\n",
        "\n",
        "# Make discriminators (D_F: distinguish real/fake full dose images / D_Q: distinguish real/fake quarter dose images)\n",
        "####################\n",
        "D_F = Discriminator(1, 128).to(device)\n",
        "D_Q = Discriminator(1, 128).to(device)\n",
        "####################\n",
        "\n",
        "print(\"G_F2Q, G_F2Q\")\n",
        "print(G_F2Q)\n",
        "\n",
        "print(\"D_F, D_Q\")\n",
        "print(D_F)\n",
        "\n",
        "\n",
        "# Make optimizers\n",
        "G_optim = torch.optim.Adam(itertools.chain(G_F2Q.parameters(), G_Q2F.parameters()), lr, betas=(beta1, beta2))\n",
        "D_optim = torch.optim.Adam(itertools.chain(D_F.parameters(), D_Q.parameters()), lr, betas=(beta1, beta2))\n",
        "\n",
        "# Define loss functions\n",
        "adv_loss = nn.MSELoss()\n",
        "cycle_loss = nn.L1Loss()\n",
        "iden_loss = nn.L1Loss()\n",
        "\n",
        "# Loss functions\n",
        "loss_name = ['G_adv_loss_F',\n",
        "             'G_adv_loss_Q',\n",
        "             'G_cycle_loss_F',\n",
        "             'G_cycle_loss_Q',\n",
        "             'G_iden_loss_F',\n",
        "             'G_iden_loss_Q',\n",
        "             'D_adv_loss_F',\n",
        "             'D_adv_loss_Q']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N5Y0vOhTVlTR"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "# Functions for caculating PSNR, SSIM\n",
        "def psnr(A, ref):\n",
        "  ref[ref < -1000] = -1000\n",
        "  A[A < -1000] = -1000\n",
        "  val_min = -1000\n",
        "  val_max = np.amax(ref)\n",
        "  # print(val_max)\n",
        "  ref = (ref - val_min) / (val_max - val_min)\n",
        "  A = (A - val_min) / (val_max - val_min)\n",
        "  out = peak_signal_noise_ratio(ref, A)\n",
        "  return out\n",
        "\n",
        "def ssim(A, ref):\n",
        "  ref[ref < -1000] = -1000\n",
        "  A[A < -1000] = -1000\n",
        "  val_min = -1000\n",
        "  val_max = np.amax(ref)\n",
        "  ref = (ref - val_min) / (val_max - val_min)\n",
        "  A = (A - val_min) / (val_max - val_min)\n",
        "  out = structural_similarity(ref, A, data_range=2)\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS2gNrsiT6vc"
      },
      "outputs": [],
      "source": [
        "from os.path import isfile\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "if isfile(join(path_checkpoint, model_name + '.pth')):\n",
        "  checkpoint = torch.load(join(path_checkpoint, model_name + '.pth'))\n",
        "  G_F2Q.load_state_dict(checkpoint['G_F2Q_state_dict'])\n",
        "  G_Q2F.load_state_dict(checkpoint['G_Q2F_state_dict'])\n",
        "  D_F.load_state_dict(checkpoint['D_F_state_dict'])\n",
        "  D_Q.load_state_dict(checkpoint['D_Q_state_dict'])\n",
        "  G_optim.load_state_dict(checkpoint['G_optim_state_dict'])\n",
        "  D_optim.load_state_dict(checkpoint['D_optim_state_dict'])\n",
        "  trained_epoch = checkpoint['epoch']\n",
        "  losses_list = {name: torch.load(join(path_result, name + '.npy')) for name in loss_name}\n",
        "  np_losses_list = {name: np.load(join(path_result, 'np_' +  name + '.npy')).tolist() for name in loss_name}\n",
        "  print('Start from save model - ' + str(trained_epoch))\n",
        "# If the checkpoint does not exist, start the training with random initialized model\n",
        "else:\n",
        "  init_weights(G_F2Q)\n",
        "  init_weights(G_Q2F)\n",
        "  init_weights(D_F)\n",
        "  init_weights(D_Q)\n",
        "  trained_epoch = 0\n",
        "  losses_list = {name: list() for name in loss_name}\n",
        "  np_losses_list = {name: list() for name in loss_name}\n",
        "  print('Start from random initialized model')\n",
        "\n",
        "for epoch in tqdm(range(trained_epoch, num_epoch), desc='Epoch', total=num_epoch, initial=trained_epoch):\n",
        "  print(\"Epoch: \", epoch+1)\n",
        "  losses = {name: Mean() for name in loss_name}\n",
        "  G_Q2F.train()\n",
        "  d_f_real = []\n",
        "  d_f_fake = []\n",
        "  d_q_real = []\n",
        "  d_q_fake = []\n",
        "\n",
        "  for x_F, x_Q, _ in tqdm(train_dataloader, desc='Step'):\n",
        "    x_F = x_F.to(device)\n",
        "    x_Q = x_Q.to(device)\n",
        "\n",
        "    # Set 'requires_grad' of the discriminators as 'False'\n",
        "    ####################\n",
        "    set_requires_grad(D_F, requires_grad=False)    \n",
        "    set_requires_grad(D_Q, requires_grad=False)\n",
        "    set_requires_grad(G_F2Q, requires_grad=True)    \n",
        "    set_requires_grad(G_Q2F, requires_grad=True)    \n",
        "    ####################\n",
        "\n",
        "    x_FQ = G_F2Q(x_F)\n",
        "    x_QF = G_Q2F(x_Q)\n",
        "    x_QFQ = G_F2Q(G_Q2F(x_Q))\n",
        "    x_FQF = G_Q2F(G_F2Q(x_F))\n",
        "    x_QQ = G_F2Q(x_Q)\n",
        "    x_FF = G_Q2F(x_F)\n",
        "\n",
        "    G_adv_loss_F = adv_loss(D_F(x_QF), torch.ones_like(D_F(x_QF)))\n",
        "    G_adv_loss_Q = adv_loss(D_Q(x_FQ), torch.ones_like(D_Q(x_QF)))\n",
        "    G_cycle_loss_F = cycle_loss(x_F, x_FQF)\n",
        "    G_cycle_loss_Q = cycle_loss(x_Q, x_QFQ)\n",
        "    G_iden_loss_F = iden_loss(x_F, x_FF)\n",
        "    G_iden_loss_Q = iden_loss(x_Q, x_QQ)\n",
        "    G_adv_loss = G_adv_loss_F + G_adv_loss_Q\n",
        "    G_cycle_loss = G_cycle_loss_F + G_cycle_loss_Q\n",
        "    G_iden_loss = G_iden_loss_F + G_iden_loss_Q\n",
        "    G_total_loss = G_adv_loss_F + G_adv_loss_Q + lambda_cycle * (G_cycle_loss) + lambda_iden * (G_iden_loss)\n",
        "\n",
        "    G_optim.zero_grad()\n",
        "    G_total_loss.backward()\n",
        "    G_optim.step()\n",
        "    \n",
        "    # Set 'requires_grad' of the discriminators as 'True'\n",
        "    ####################\n",
        "    set_requires_grad(G_F2Q, requires_grad=False)\n",
        "    set_requires_grad(G_Q2F, requires_grad=False)\n",
        "    set_requires_grad(D_F, requires_grad=True)\n",
        "    set_requires_grad(D_Q, requires_grad=True)\n",
        "    ####################\n",
        "\n",
        "    # You have to detach the outputs of the generators in below codes\n",
        "\n",
        "\n",
        "    D_adv_loss_F = adv_loss(D_F(x_F), torch.ones_like(D_F(x_F))) + torch.mean(D_F(x_QF.detach())**2)\n",
        "    D_adv_loss_Q = adv_loss(D_Q(x_Q), torch.ones_like(D_Q(x_Q))) + torch.mean(D_Q(x_FQ.detach())**2)\n",
        "    d_f_real.append(adv_loss(D_F(x_F), torch.ones_like(D_F(x_F))).detach().cpu().numpy())\n",
        "    d_f_fake.append(torch.mean(D_F(x_QF)).detach().cpu().numpy()**2)\n",
        "    d_q_real.append(adv_loss(D_Q(x_Q), torch.ones_like(D_Q(x_Q))).detach().cpu().numpy())\n",
        "    d_q_fake.append(torch.mean(D_Q(x_FQ)).detach().cpu().numpy()**2)\n",
        "\n",
        "    #thum_code\n",
        "    D_total_loss_F = D_adv_loss_F / 2.0\n",
        "    D_total_loss_Q = D_adv_loss_Q / 2.0\n",
        "    D_total_loss = D_total_loss_F + D_total_loss_Q\n",
        "\n",
        "    D_optim.zero_grad()\n",
        "    D_total_loss_F.backward()\n",
        "    D_total_loss_Q.backward()\n",
        "    D_optim.step()\n",
        "\n",
        "    # Calculate the average loss during one epoch\n",
        "    losses['G_adv_loss_F'](G_adv_loss_F.detach())\n",
        "    losses['G_adv_loss_Q'](G_adv_loss_Q.detach())\n",
        "    losses['G_cycle_loss_F'](G_cycle_loss_F.detach())\n",
        "    losses['G_cycle_loss_Q'](G_cycle_loss_Q.detach())\n",
        "    losses['G_iden_loss_F'](G_iden_loss_F.detach())\n",
        "    losses['G_iden_loss_Q'](G_iden_loss_Q.detach())\n",
        "    losses['D_adv_loss_F'](D_adv_loss_F.detach())\n",
        "    losses['D_adv_loss_Q'](D_adv_loss_Q.detach())\n",
        "  \n",
        "  for name in loss_name:\n",
        "    losses_list[name].append(losses[name].result())\n",
        "    torch.save(losses_list[name], join(path_result, name + '.npy'))\n",
        "    print(\"name: \", name, losses[name].result().cpu().numpy())\n",
        "    np_losses_list[name].append(losses[name].result().cpu().numpy())\n",
        "    np.save(join(path_result, 'np_' + name + '.npy'), (np_losses_list[name]))\n",
        "  print(\"---seperate loss---\")\n",
        "  print(\"avg_d_f_real: \", sum(d_f_real)/(120))\n",
        "  print(\"avg_d_f_fake: \", sum(d_f_fake)/(120))\n",
        "  print(\"avg_d_q_real: \", sum(d_q_real)/(120))\n",
        "  print(\"avg_d_q_fake: \", sum(d_q_fake)/(120))\n",
        "\n",
        "\n",
        "  # Save the trained model and list of losses\n",
        "  torch.save({'epoch': epoch + 1, 'G_F2Q_state_dict': G_F2Q.state_dict(), 'G_Q2F_state_dict': G_Q2F.state_dict(),\n",
        "              'D_F_state_dict': D_F.state_dict(), 'D_Q_state_dict': D_Q.state_dict(),\n",
        "              'G_optim_state_dict': G_optim.state_dict(), 'D_optim_state_dict': D_optim.state_dict()}, join(path_checkpoint, model_name + '.pth'))\n",
        "\n",
        "  # for test \n",
        "  test = np.load(join(path_result, \"np_D_adv_loss_Q\" + '.npy'))\n",
        "  print(len(test))\n",
        "  print(test)\n",
        "\n",
        "  # Plot input/output images every 10 epochs\n",
        "  imgs = [x_F[0].detach().cpu().numpy(), x_FQ[0].detach().cpu().numpy(), x_FQF[0].detach().cpu().numpy(),\n",
        "          x_Q[0].detach().cpu().numpy(), x_QF[0].detach().cpu().numpy(), x_QFQ[0].detach().cpu().numpy()]\n",
        "  show_imgs(imgs, path_image, epoch+1)\n",
        "\n",
        "# log per 5epochs \n",
        "  if (epoch+1)%5 == 0:\n",
        "    torch.save({'epoch': epoch + 1, 'G_F2Q_state_dict': G_F2Q.state_dict(), 'G_Q2F_state_dict': G_Q2F.state_dict(),\n",
        "            'D_F_state_dict': D_F.state_dict(), 'D_Q_state_dict': D_Q.state_dict(),\n",
        "            'G_optim_state_dict': G_optim.state_dict(), 'D_optim_state_dict': D_optim.state_dict()}, join(path_checkpoint, model_name + f'_{str(epoch+1)}.pth'))\n",
        "    G_Q2F.eval()\n",
        "    # make G_Q2F evaluation mode\n",
        "    # Test and save\n",
        "    with torch.no_grad():\n",
        "      for _, x_Q, file_name in tqdm(test_dataloader):\n",
        "        x_Q = x_Q.to(device)\n",
        "        x_QF = G_Q2F(x_Q)[0].detach().cpu().numpy()\n",
        "        x_QF = x_QF * 4000\n",
        "\n",
        "        np.save(join(path_result, file_name[0]), x_QF)\n",
        "\n",
        "    avg_original_psnr = []\n",
        "    avg_original_ssim = []\n",
        "    avg_model_out_psnr = []\n",
        "    avg_model_out_ssim = []\n",
        "\n",
        "    #save test dataset output.\n",
        "    for i in range(1, 422):\n",
        "        # How to use functions 'psnr' and 'ssim'\n",
        "        path_quarter = os.path.join(path_data, f'test/quarter_dose/{i}.npy')\n",
        "        path_full = os.path.join(path_data, f'test/full_dose/{i}.npy')\n",
        "        path_output = os.path.join(path_result, f'{i}.npy')\n",
        "\n",
        "        quarter = np.load(path_quarter)\n",
        "        full = np.load(path_full)\n",
        "        output = np.load(path_output)\n",
        "        output = output.squeeze()\n",
        "\n",
        "        quarter = (quarter - 0.0192) / 0.0192 * 1000\n",
        "        full = (full - 0.0192) / 0.0192 * 1000\n",
        "\n",
        "        # print(psnr(quarter, full), \"|\" , psnr(output,full))\n",
        "        # print(ssim(quarter, full), \"|\" , ssim(output,full))\n",
        "\n",
        "        avg_original_psnr.append(psnr(quarter, full))\n",
        "        avg_original_ssim.append(ssim(quarter, full))\n",
        "        avg_model_out_psnr.append(psnr(output, full))\n",
        "        avg_model_out_ssim.append(ssim(output, full))\n",
        "\n",
        "    print(\"average score of original psnr: \", sum(avg_original_psnr)/421.0)\n",
        "    print(\"average score of model output psnr: \", sum(avg_model_out_psnr)/421.0)\n",
        "    print(\"average score of original ssim: \", sum(avg_original_ssim)/421.0)\n",
        "    print(\"average score of model output ssim: \", sum(avg_model_out_ssim)/421.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GbriABk6EG4"
      },
      "source": [
        "## V. Test\n",
        "Last, you have to verify the performance of your network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WF5Lsovgf9E"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 43/421 [00:01<00:13, 28.26it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 421/421 [00:13<00:00, 30.19it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# average score of original psnr:  34.16952392478545\n",
        "# average score of model output psnr:  34.16922081448021\n",
        "# average score of original ssim:  0.8931997874844589\n",
        "# average score of model output psnr:  0.8930020681009424\n",
        "\n",
        "# Load the last checkpoint\n",
        "checkpoint = torch.load(join(path_checkpoint, model_name + '.pth'))\n",
        "G_Q2F.load_state_dict(checkpoint['G_Q2F_state_dict'])\n",
        "G_Q2F.eval()\n",
        "\n",
        "# Test and save\n",
        "with torch.no_grad():\n",
        "  for _, x_Q, file_name in tqdm(test_dataloader):\n",
        "    x_Q = x_Q.to(device)\n",
        "    x_QF = G_Q2F(x_Q)[0].detach().cpu().numpy()\n",
        "    x_QF = x_QF * 4000\n",
        "\n",
        "    np.save(join(path_result, file_name[0]), x_QF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 421/421 [00:11<00:00, 35.99it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#G_F2Q output was lower than G_Q2F\n",
        "# average score of original psnr:  34.16952392478545\n",
        "# average score of model output psnr:  34.16860601308719\n",
        "# average score of original ssim:  0.8931997874844589\n",
        "# average score of model output psnr:  0.8930985633512346\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Load the last checkpoint\n",
        "checkpoint = torch.load(join(path_checkpoint, model_name + '.pth'))\n",
        "G_F2Q.load_state_dict(checkpoint['G_F2Q_state_dict'])\n",
        "G_F2Q.eval()\n",
        "\n",
        "# Test and save\n",
        "with torch.no_grad():\n",
        "  for _, x_Q, file_name in tqdm(test_dataloader):\n",
        "    x_Q = x_Q.to(device)\n",
        "    x_QF = G_F2Q(x_Q)[0].detach().cpu().numpy()\n",
        "    x_QF = x_QF * 4000\n",
        "\n",
        "    np.save(join(path_result, file_name[0]), x_QF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3qdb21fGOSi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot loss graph (adversarial loss)\n",
        "# x_axis = np.arange(1, num_epoch + 1)\n",
        "#thum_code\n",
        "x_axis = np.arange(1, 201)\n",
        "plt.figure(1)\n",
        "for name in ['np_G_adv_loss_F', 'np_G_adv_loss_Q', 'np_D_adv_loss_F', 'np_D_adv_loss_Q']:\n",
        "  loss_arr = np.load(join(path_result, name + '.npy'))\n",
        "  plt.plot(x_axis, loss_arr, label=name)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.savefig(join(path_result, 'loss_curve_1.png'))\n",
        "plt.show()\n",
        "\n",
        "# Plot loss graph (cycle consistency loss, identity loss)\n",
        "plt.figure(2)\n",
        "for name in ['np_G_cycle_loss_F', 'np_G_cycle_loss_Q', 'np_G_iden_loss_F', 'np_G_iden_loss_Q']:\n",
        "  loss_arr = np.load(join(path_result, name + '.npy'))\n",
        "  # loss_arr.detach()\n",
        "  plt.plot(x_axis, loss_arr, label=name)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.savefig(join(path_result, 'loss_curve_2.png'))\n",
        "plt.show()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgMYN7B_nsdu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from os.path import join as join\n",
        "\n",
        "# Example of result\n",
        "path_quarter = join(path_data, 'test/quarter_dose/4.npy')\n",
        "path_full = join(path_data, 'test/full_dose/4.npy')\n",
        "path_output = join(path_result, '4.npy')\n",
        "\n",
        "quarter = np.load(path_quarter)\n",
        "full = np.load(path_full)\n",
        "output = np.load(path_output)\n",
        "\n",
        "quarter = (quarter - 0.0192) / 0.0192 * 1000\n",
        "full = (full - 0.0192) / 0.0192 * 1000\n",
        "\n",
        "quarter = np.clip(quarter, -1000, 1000)\n",
        "full = np.clip(full, -1000, 1000)\n",
        "output = np.clip(output, -1000, 1000)\n",
        "\n",
        "plt.imshow(quarter, cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(full, cmap='gray')\n",
        "plt.show()\n",
        "# print(full.shape)\n",
        "# print(quarter.shape)\n",
        "# print(output.shape)\n",
        "plt.imshow(output.squeeze(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "avg_original_psnr = []\n",
        "avg_original_ssim = []\n",
        "avg_model_out_psnr = []\n",
        "avg_model_out_ssim = []\n",
        "\n",
        "for i in range(1, 422):\n",
        "    print(i)\n",
        "    # How to use functions 'psnr' and 'ssim'\n",
        "    path_quarter = os.path.join(path_data, f'test/quarter_dose/{i}.npy')\n",
        "    path_full = os.path.join(path_data, f'test/full_dose/{i}.npy')\n",
        "    path_output = os.path.join(path_result, f'{i}.npy')\n",
        "\n",
        "    quarter = np.load(path_quarter)\n",
        "    full = np.load(path_full)\n",
        "    output = np.load(path_output)\n",
        "    output = output.squeeze()\n",
        "\n",
        "    quarter = (quarter - 0.0192) / 0.0192 * 1000\n",
        "    full = (full - 0.0192) / 0.0192 * 1000\n",
        "\n",
        "\n",
        "    print(psnr(quarter, full), \"|\" , psnr(output,full))\n",
        "    print(ssim(quarter, full), \"|\" , ssim(output,full))\n",
        "\n",
        "    avg_original_psnr.append(psnr(quarter, full))\n",
        "    avg_original_ssim.append(ssim(quarter, full))\n",
        "    avg_model_out_psnr.append(psnr(output, full))\n",
        "    avg_model_out_ssim.append(ssim(output, full))\n",
        "\n",
        "print(\"average score of original psnr: \", sum(avg_original_psnr)/421.0)\n",
        "print(\"average score of model output psnr: \", sum(avg_model_out_psnr)/421.0)\n",
        "print(\"average score of original ssim: \", sum(avg_original_ssim)/421.0)\n",
        "print(\"average score of model output psnr: \", sum(avg_model_out_ssim)/421.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[BiS800]Project2_cycleGAN (for students).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
